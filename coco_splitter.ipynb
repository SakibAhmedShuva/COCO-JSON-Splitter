{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_coco_dataset(\n",
    "    coco_json_path,\n",
    "    image_dir,\n",
    "    output_dir,\n",
    "    train_split=0.7,\n",
    "    val_split=0.2,\n",
    "    test_split=0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Split COCO dataset into train, validation and test sets.\n",
    "    \n",
    "    Args:\n",
    "        coco_json_path (str): Path to COCO JSON file\n",
    "        image_dir (str): Directory containing images\n",
    "        output_dir (str): Directory to save split datasets\n",
    "        train_split (float): Proportion of data for training (default: 0.7)\n",
    "        val_split (float): Proportion of data for validation (default: 0.2)\n",
    "        test_split (float): Proportion of data for testing (default: 0.1)\n",
    "    \"\"\"\n",
    "    # Validate split ratios\n",
    "    if abs(train_split + val_split + test_split - 1.0) > 1e-10:\n",
    "        raise ValueError(\"Split ratios must sum to 1\")\n",
    "\n",
    "    # Read COCO JSON file\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    # Create output directories\n",
    "    splits = ['train', 'val'] if test_split == 0 else ['train', 'val', 'test']\n",
    "    split_dirs = {}\n",
    "    for split in splits:\n",
    "        split_dirs[split] = os.path.join(output_dir, split)\n",
    "        os.makedirs(split_dirs[split], exist_ok=True)\n",
    "        os.makedirs(os.path.join(split_dirs[split], 'images'), exist_ok=True)\n",
    "\n",
    "    # Split images\n",
    "    images = coco_data['images']\n",
    "    \n",
    "    if test_split == 0:\n",
    "        # Binary split between train and val\n",
    "        train_images, val_images = train_test_split(\n",
    "            images, \n",
    "            train_size=train_split,\n",
    "            test_size=val_split,\n",
    "            random_state=42\n",
    "        )\n",
    "        test_images = []  # Empty list for test set\n",
    "    else:\n",
    "        # Three-way split\n",
    "        train_images, temp_images = train_test_split(\n",
    "            images, \n",
    "            train_size=train_split,\n",
    "            random_state=42\n",
    "        )\n",
    "        relative_val_ratio = val_split / (val_split + test_split)\n",
    "        val_images, test_images = train_test_split(\n",
    "            temp_images,\n",
    "            train_size=relative_val_ratio,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    split_images = {\n",
    "        'train': train_images,\n",
    "        'val': val_images,\n",
    "        'test': test_images\n",
    "    }\n",
    "\n",
    "    # Create split datasets\n",
    "    for split_name, split_imgs in split_images.items():\n",
    "        # Skip test split if test_split is 0\n",
    "        if test_split == 0 and split_name == 'test':\n",
    "            continue\n",
    "            \n",
    "        # Create new COCO data structure\n",
    "        split_coco = {\n",
    "            'info': coco_data.get('info', {}),\n",
    "            'licenses': coco_data.get('licenses', []),\n",
    "            'categories': coco_data.get('categories', []),\n",
    "            'images': split_imgs,\n",
    "            'annotations': []\n",
    "        }\n",
    "\n",
    "        # Get image IDs for this split\n",
    "        split_image_ids = {img['id'] for img in split_imgs}\n",
    "\n",
    "        # Filter annotations for images in this split\n",
    "        split_coco['annotations'] = [\n",
    "            ann for ann in coco_data.get('annotations', [])\n",
    "            if ann['image_id'] in split_image_ids\n",
    "        ]\n",
    "\n",
    "        # Save JSON\n",
    "        split_json_path = os.path.join(split_dirs[split_name], f'instances_{split_name}.json')\n",
    "        with open(split_json_path, 'w') as f:\n",
    "            json.dump(split_coco, f, indent=2)\n",
    "\n",
    "        # Copy images\n",
    "        for img in split_imgs:\n",
    "            src_path = os.path.join(image_dir, img['file_name'])\n",
    "            dst_path = os.path.join(split_dirs[split_name], 'images', img['file_name'])\n",
    "            if os.path.exists(src_path):\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "            else:\n",
    "                print(f\"Warning: Image not found: {src_path}\")\n",
    "\n",
    "        print(f\"{split_name} set:\")\n",
    "        print(f\"  Images: {len(split_imgs)}\")\n",
    "        print(f\"  Annotations: {len(split_coco['annotations'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:\n",
      "  Images: 885\n",
      "  Annotations: 25131\n",
      "\n",
      "val set:\n",
      "  Images: 222\n",
      "  Annotations: 7435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage - just modify these paths according to your setup\n",
    "coco_json_path = r'd:\\OneDrive - Personal\\DS\\FleetBlox\\Data\\Final\\Inspection\\Exterior\\Exterior Damage Final COCO (Augmented) Label Names Corrected\\annotations\\instances_default.json'\n",
    "image_dir = r'D:\\OneDrive - Personal\\DS\\FleetBlox\\Data\\Final\\Inspection\\Exterior\\Exterior Damage Final COCO (Augmented) Label Names Corrected\\images'\n",
    "output_dir = r'D:\\OneDrive - Personal\\DS\\FleetBlox\\Data\\Final\\Inspection\\Exterior\\splitted'\n",
    "\n",
    "# Run the splitting function\n",
    "split_coco_dataset(\n",
    "    coco_json_path=coco_json_path,\n",
    "    image_dir=image_dir,\n",
    "    output_dir=output_dir,\n",
    "    train_split=0.8,\n",
    "    val_split=0.2,\n",
    "    test_split=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
